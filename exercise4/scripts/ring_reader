#!/usr/bin/env python
from __future__ import print_function
 
import roslib
# roslib.load_manifest('exercise4')
import sys
import rospy
#import cv2
import tf
import numpy as np
import tf2_geometry_msgs
import tf2_ros
#from math import sqrt
from sensor_msgs.msg import Image
from geometry_msgs.msg import PointStamped, Vector3, Pose
from cv_bridge import CvBridge, CvBridgeError
from visualization_msgs.msg import Marker, MarkerArray
from std_msgs.msg import ColorRGBA
from std_msgs.msg import String
from RingReader_local import *

dictm = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)

bridge = CvBridge()
def ratio(e1,e2):

        (x1,y1), (Ma1, ma1), angle1 = e1 
        (x2,y2), (Ma2, ma2), angle2 = e2 

        a1 = ma1/2
        a2 = ma2/2
        r1 = 0

        b1 = Ma1/2
        b2 = Ma2/2
        r2 = 0

        if b1 == 0 or b2 == 0 or a1 == 0 or a2 == 0:
            return False
        size = (e1[1][0]+e1[1][1])/2
        center = (e1[0][1], e1[0][0])
       
        r2 = 0

        if b1 < b2:
            
            r2 = b2/b1
        else:
            r2 = b1/b2
        
        if a1 < a2:
            r1 = a2/a1
        else:
            r1 = a1/a2
        #print("r", r)
        if r1 > 1.2 and r1 < 1.5:
            if r2 > 1.2 and r2 < 1.5:
                return True
        return False

def map_goals_callback(data):
    #self.time_rec = data.header.stamp
    #print('Iam here!')
    #rospy.loginfo(self.counter)
    data = rospy.wait_for_message('/camera/rgb/image_color', Image)
    try:
        cv_image = bridge.imgmsg_to_cv2(data, "bgr8")
            
    except CvBridgeError as e:
        print(e)

    # Set the dimensions of the image
    dims = cv_image.shape
    cv_image = cv_image[60:360, 0:dims[1]]
    #print(self.dims)
    #gledamo y = 50 do 320

    # Tranform image to gayscale
    gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)

    # Do histogram equlization
    img = cv2.equalizeHist(gray)

    # Binarize the image
    #ret, thresh = cv2.threshol  #     print cnt.shape
    #print(cnt)

    # Binarize the image
    #ret, thresh = cv2.threshold(img, 60, 255, 0)
    thresh = cv2.Canny(img,100,200)
    #cv2.imshow("Binary window", thresh)



    # Extract contours
    contours_, contours, hierarchy = cv2.findContours(thresh, 2, 2)

    # Example how to draw the contours
    #cv2.drawContours(cv_image, contours, -1, (0, 0, 255), 3)

    # Fit elipses to all extracted contours
    elps = []
    for cnt in contours:
        #     print cnt
        #     print cnt.shape
        #print(cnt)
        if cnt.shape[0] >= 60:
            ellipse = cv2.fitEllipse(cnt)

            elps.append(ellipse)
            #cv2.drawContours(cv_image, cnt, -1, (255, 0, 0), 3)
            #cv2.ellipse(cv_image, ellipse, (255, 0, 0), 2)


    # Find two elipses with same centers
    candidates = []
    for n in range(len(elps)):
        for m in range(n + 1, len(elps)):
            e1 = elps[n]
            e2 = elps[m]



            dist = np.sqrt(((e1[0][0] - e2[0][0]) ** 2 + (e1[0][1] - e2[0][1]) ** 2))
            #             print dist
            if dist < 5 and ratio(e1,e2):
                candidates.append((e1,e2))

    try:
        depth_img = rospy.wait_for_message('/camera/depth_registered/image_raw', Image)
    except Exception as e:
        print(e)

    #depth_img = depth_img[60:330, 0:self.dims[1]]

    # Extract the depth from the depth image
    for c in candidates:

        e1 = c[0]
        e2 = c[1]


        #cv2.ellipse(cv_image, e1, (0, 255, 0), 2)
        #cv2.ellipse(cv_image, e2, (0, 255, 0), 2)

        size = (e1[1][0]+e1[1][1])/2
        center = (e1[0][1], e1[0][0])

        x1 = int(center[0] - size / 2)
        x2 = int(center[0] + size / 2)
        x_min = x1 if x1>0 else 0
        x_max = x2 if x2<cv_image.shape[0] else cv_image.shape[0]

        y1 = int(center[1] - size / 2)
        y2 = int(center[1] + size / 2)
        y_min = y1 if y1 > 0 else 0
        y_max = y2 if y2 < cv_image.shape[1] else cv_imagecv_image.shape[1]

    if len(candidates)>1:
        print('Ring detected! (hopefully)')
        corners, ids, _ = cv2.aruco.detectMarkers(cv_image,dictm)
        
        # Increase proportionally if you want a larger image
        image_size=(351,248,3)
        marker_side=50

        img_out = np.zeros(image_size, np.uint8)
        out_pts = np.array([[marker_side/2,img_out.shape[0]-marker_side/2],
                            [img_out.shape[1]-marker_side/2,img_out.shape[0]-marker_side/2],
                            [marker_side/2,marker_side/2],
                            [img_out.shape[1]-marker_side/2,marker_side/2]])

        src_points = np.zeros((4,2))
        cens_mars = np.zeros((4,2))

        if not ids is None:
            if len(ids)==4:
                print('4 Markers detected')
        
                for idx in ids:
                    # Calculate the center point of all markers
                    cors = np.squeeze(corners[idx[0]-1])
                    cen_mar = np.mean(cors,axis=0)
                    cens_mars[idx[0]-1]=cen_mar
                    cen_point = np.mean(cens_mars,axis=0)
            
                for coords in cens_mars:
                    #  Map the correct source points
                    if coords[0]<cen_point[0] and coords[1]<cen_point[1]:
                        src_points[2]=coords
                    elif coords[0]<cen_point[0] and coords[1]>cen_point[1]:
                        src_points[0]=coords
                    elif coords[0]>cen_point[0] and coords[1]<cen_point[1]:
                        src_points[3]=coords
                    else:
                        src_points[1]=coords

                h, status = cv2.findHomography(src_points, out_pts)
                img_out = cv2.warpPerspective(cv_image, h, (img_out.shape[1],img_out.shape[0]))
                
                cv2.imshow('Warped image',img_out)
                cv2.waitKey(1)

                img_msg = bridge.cv2_to_imgmsg(img_out, encoding="bgr8")

                print(extract_data(img_out))

                
            else:
                print('The number of markers is not ok:',len(ids))
        else:
            print('No markers found')
    
    elif len(candidates)==0:
        print('No contours detected')
    else:
        print('Some contours detected, not sure if it is a ring',len(candidates))
        for elps in candidates:
            e1 = elps[0]
            e2 = elps[0]
            cv2.ellipse(cv_image,e1,(0,255,0),3)
            cv2.ellipse(cv_image,e2,(0,255,0),3)

    #cv2.imshow('Image',cv_image)
    #cv2.waitKey(1)


if __name__ == '__main__':
    print("init")
    rospy.init_node('ring_reader', anonymous=False)
    marker_sub = rospy.Subscriber("homography_image_2", String, map_goals_callback)

    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")




